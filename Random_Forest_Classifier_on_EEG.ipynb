{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the folders containing the EEG data\n",
    "folders = {\n",
    "    'complex_math': r'G:\\University\\Project_Intermship\\An EEG Recordings Dataset for Mental Stress Detection\\An EEG Recordings Dataset for Mental Stress Detection\\clean data\\CSVs\\Complex Mathematical Problem solving (CMPS)',\n",
    "    'horror': r'G:\\University\\Project_Intermship\\An EEG Recordings Dataset for Mental Stress Detection\\An EEG Recordings Dataset for Mental Stress Detection\\clean data\\CSVs\\Horrer Video Stimulation',\n",
    "    'mental_test': r'G:\\University\\Project_Intermship\\An EEG Recordings Dataset for Mental Stress Detection\\An EEG Recordings Dataset for Mental Stress Detection\\clean data\\CSVs\\Trier Mental Challenge Test (TMCT)'\n",
    "}\n",
    "\n",
    "# Initialize lists to store the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Find the maximum sequence length\n",
    "max_length = 0\n",
    "for folder in folders.values():\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            max_length = max(max_length, len(df))\n",
    "\n",
    "# Loop through each folder and read the CSV files\n",
    "for label, folder in folders.items():\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            filepath = os.path.join(folder, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            # Convert DataFrame to a NumPy array\n",
    "            array = df.values\n",
    "            # Pad the array to the maximum length with zeros\n",
    "            if len(array) < max_length:\n",
    "                padded_array = np.pad(array, ((0, max_length - len(array)), (0, 0)), mode='constant')\n",
    "            else:\n",
    "                padded_array = array\n",
    "            data.append(padded_array.flatten())\n",
    "            labels.append(label)\n",
    "\n",
    "# Convert the data and labels into NumPy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode the labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "complex_math       1.00      0.29      0.44         7\n",
      "      horror       1.00      1.00      1.00         6\n",
      " mental_test       0.62      1.00      0.76         8\n",
      "\n",
      "    accuracy                           0.76        21\n",
      "   macro avg       0.87      0.76      0.74        21\n",
      "weighted avg       0.85      0.76      0.72        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train a Random Forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Labels: ['mental_test', 'horror', 'mental_test', 'horror', 'complex_math', 'complex_math', 'mental_test', 'complex_math', 'complex_math', 'mental_test', 'horror', 'horror', 'horror', 'complex_math', 'complex_math', 'mental_test', 'mental_test', 'complex_math', 'horror', 'horror', 'complex_math', 'horror', 'mental_test', 'mental_test', 'complex_math', 'complex_math', 'mental_test', 'horror', 'mental_test', 'horror']\n",
      "Predicted Labels: ['mental_test', 'horror', 'mental_test', 'horror', 'complex_math', 'complex_math', 'mental_test', 'complex_math', 'complex_math', 'mental_test', 'horror', 'horror', 'horror', 'complex_math', 'mental_test', 'mental_test', 'mental_test', 'mental_test', 'horror', 'horror', 'complex_math', 'horror', 'mental_test', 'mental_test', 'complex_math', 'mental_test', 'mental_test', 'horror', 'mental_test', 'horror']\n",
      "Overall Incorrect Rate: 0.10\n",
      "Total Test Samples: 30\n",
      "Incorrect Rate for complex_math: 0.30\n",
      "Incorrect Rate for horror: 0.00\n",
      "Incorrect Rate for mental_test: 0.00\n"
     ]
    }
   ],
   "source": [
    "def test_model_random_combination(folders, classifier, label_encoder, max_length, num_samples=1):\n",
    "    # Initialize lists to store the real and predicted labels\n",
    "    real_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    # Initialize dictionaries to track incorrect predictions for each condition\n",
    "    incorrect_counts = {label: 0 for label in folders.keys()}\n",
    "    total_counts = {label: 0 for label in folders.keys()}\n",
    "    \n",
    "    # Gather all selected samples into a list\n",
    "    samples = []\n",
    "    \n",
    "    # Loop over each condition\n",
    "    for label, folder in folders.items():\n",
    "        filenames = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "        \n",
    "        # Randomly select the specified number of CSV files\n",
    "        selected_filenames = random.sample(filenames, num_samples)\n",
    "        \n",
    "        for random_filename in selected_filenames:\n",
    "            filepath = os.path.join(folder, random_filename)\n",
    "            samples.append((label, filepath))\n",
    "    \n",
    "    # Shuffle the samples list to randomize the order\n",
    "    random.shuffle(samples)\n",
    "    \n",
    "    # Process each sample in the shuffled list\n",
    "    for label, filepath in samples:\n",
    "        df = pd.read_csv(filepath)\n",
    "        array = df.values\n",
    "        \n",
    "        # Ensure the data has the same length as the training data\n",
    "        if len(array) < max_length:\n",
    "            padded_array = np.pad(array, ((0, max_length - len(array)), (0, 0)), mode='constant')\n",
    "        else:\n",
    "            padded_array = array[:max_length]\n",
    "        \n",
    "        # Flatten the data to match the model's expected input\n",
    "        test_data = padded_array.flatten().reshape(1, -1)\n",
    "        \n",
    "        # Predict the condition using the trained model\n",
    "        predicted_label_encoded = classifier.predict(test_data)\n",
    "        predicted_label = label_encoder.inverse_transform(predicted_label_encoded)\n",
    "        \n",
    "        # Store the real and predicted labels\n",
    "        real_labels.append(label)\n",
    "        predicted_labels.append(predicted_label[0])\n",
    "        \n",
    "        # Update counts for the current condition\n",
    "        total_counts[label] += 1\n",
    "        if label != predicted_label[0]:\n",
    "            incorrect_counts[label] += 1\n",
    "    \n",
    "    # Calculate the overall incorrect rate\n",
    "    incorrect_predictions = sum(incorrect_counts.values())\n",
    "    incorrect_rate = incorrect_predictions / len(real_labels)\n",
    "    \n",
    "    # Print the real and predicted labels\n",
    "    print(f'Real Labels: {real_labels}')\n",
    "    print(f'Predicted Labels: {predicted_labels}')\n",
    "    print(f'Overall Incorrect Rate: {incorrect_rate:.2f}')\n",
    "    print(f'Total Test Samples: {len(real_labels)}')\n",
    "    \n",
    "    # Print incorrect rates for each condition\n",
    "    for label in folders.keys():\n",
    "        condition_incorrect_rate = incorrect_counts[label] / total_counts[label] if total_counts[label] > 0 else 0\n",
    "        print(f'Incorrect Rate for {label}: {condition_incorrect_rate:.2f}')\n",
    "\n",
    "# Example usage: test with 22 samples from each condition\n",
    "test_model_random_combination(folders, classifier, label_encoder, max_length, num_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Incorrect Rate for complex_math over 10 repeats: 0.22\n",
      "Average Incorrect Rate for horror over 10 repeats: 0.00\n",
      "Average Incorrect Rate for mental_test over 10 repeats: 0.00\n",
      "Overall Average Incorrect Rate over 10 repeats: 0.07\n"
     ]
    }
   ],
   "source": [
    "def test_model_multiple_repeats(folders, classifier, label_encoder, max_length, num_samples=1, num_repeats=10):\n",
    "    # Initialize a dictionary to store incorrect rates for each condition across repeats\n",
    "    condition_incorrect_rates = {label: [] for label in folders.keys()}\n",
    "    overall_incorrect_rates = []\n",
    "    \n",
    "    # Repeat the process num_repeats times\n",
    "    for _ in range(num_repeats):\n",
    "        # Initialize dictionaries to track incorrect predictions for each condition\n",
    "        incorrect_counts = {label: 0 for label in folders.keys()}\n",
    "        total_counts = {label: 0 for label in folders.keys()}\n",
    "        \n",
    "        # Gather all selected samples into a list\n",
    "        samples = []\n",
    "        \n",
    "        # Loop over each condition\n",
    "        for label, folder in folders.items():\n",
    "            filenames = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "            \n",
    "            # Randomly select the specified number of CSV files\n",
    "            selected_filenames = random.sample(filenames, num_samples)\n",
    "            \n",
    "            for random_filename in selected_filenames:\n",
    "                filepath = os.path.join(folder, random_filename)\n",
    "                samples.append((label, filepath))\n",
    "        \n",
    "        # Shuffle the samples list to randomize the order\n",
    "        random.shuffle(samples)\n",
    "        \n",
    "        # Process each sample in the shuffled list\n",
    "        for label, filepath in samples:\n",
    "            df = pd.read_csv(filepath)\n",
    "            array = df.values\n",
    "            \n",
    "            # Ensure the data has the same length as the training data\n",
    "            if len(array) < max_length:\n",
    "                padded_array = np.pad(array, ((0, max_length - len(array)), (0, 0)), mode='constant')\n",
    "            else:\n",
    "                padded_array = array[:max_length]\n",
    "            \n",
    "            # Flatten the data to match the model's expected input\n",
    "            test_data = padded_array.flatten().reshape(1, -1)\n",
    "            \n",
    "            # Predict the condition using the trained model\n",
    "            predicted_label_encoded = classifier.predict(test_data)\n",
    "            predicted_label = label_encoder.inverse_transform(predicted_label_encoded)\n",
    "            \n",
    "            # Update counts for the current condition\n",
    "            total_counts[label] += 1\n",
    "            if label != predicted_label[0]:\n",
    "                incorrect_counts[label] += 1\n",
    "        \n",
    "        # Calculate the incorrect rate for each condition in this repeat\n",
    "        for label in folders.keys():\n",
    "            condition_incorrect_rate = incorrect_counts[label] / total_counts[label] if total_counts[label] > 0 else 0\n",
    "            condition_incorrect_rates[label].append(condition_incorrect_rate)\n",
    "        \n",
    "        # Calculate the overall incorrect rate for this repeat\n",
    "        incorrect_predictions = sum(incorrect_counts.values())\n",
    "        overall_incorrect_rate = incorrect_predictions / sum(total_counts.values())\n",
    "        overall_incorrect_rates.append(overall_incorrect_rate)\n",
    "    \n",
    "    # Calculate and print the average incorrect rate for each condition across all repeats\n",
    "    for label in folders.keys():\n",
    "        average_incorrect_rate = sum(condition_incorrect_rates[label]) / num_repeats\n",
    "        print(f'Average Incorrect Rate for {label} over {num_repeats} repeats: {average_incorrect_rate:.2f}')\n",
    "    \n",
    "    # Calculate and print the overall average incorrect rate across all conditions\n",
    "    overall_average_incorrect_rate = sum(overall_incorrect_rates) / num_repeats\n",
    "    print(f'Overall Average Incorrect Rate over {num_repeats} repeats: {overall_average_incorrect_rate:.2f}')\n",
    "\n",
    "# Example usage: test with 22 samples from each condition, repeated 10 times\n",
    "test_model_multiple_repeats(folders, classifier, label_encoder, max_length, num_samples=5, num_repeats=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
